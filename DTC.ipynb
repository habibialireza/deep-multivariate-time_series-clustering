{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184b3954",
      "metadata": {
        "id": "184b3954"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\"\n",
        "response = requests.get(URL)\n",
        "open(\"har.zip\", \"wb\").write(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D14SlSwXcjN",
        "outputId": "56751d6e-addf-4803-b0d3-72890aea6a6d"
      },
      "id": "3D14SlSwXcjN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60999314"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"har.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "    "
      ],
      "metadata": {
        "id": "_25w7q7EYJGK"
      },
      "id": "_25w7q7EYJGK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"./UCI HAR Dataset/test/X_test.txt\", \"r\")\n",
        "array = []\n",
        "line = f.readline()\n",
        "index = 0\n",
        "while line:\n",
        "    line = line.strip(\"\\n\")\n",
        "    line = line.split()\n",
        "    array.append([])\n",
        "    for item in line:\n",
        "        array[index].append(float(item))\n",
        "    line = f.readline()\n",
        "    index += 1\n",
        "f.close()\n",
        "\n",
        "xy=np.array(array)\n",
        "xy=xy.astype(np.float64)\n",
        "print(xy.shape)\n",
        "x_test = torch.from_numpy(xy[:, :])\n",
        "print (x_test)\n",
        "\n",
        "f = open(\"./UCI HAR Dataset/test/y_test.txt\", \"r\")\n",
        "array = []\n",
        "line = f.readline()\n",
        "index = 0\n",
        "while line:\n",
        "    line = line.strip(\"\\n\")\n",
        "    line = line.split()\n",
        "    array.append([])\n",
        "    for item in line:\n",
        "        array[index].append(float(item))\n",
        "    line = f.readline()\n",
        "    index += 1\n",
        "f.close()\n",
        "\n",
        "xy=np.array(array)\n",
        "xy=xy.astype(np.float64)\n",
        "\n",
        "print(xy.shape)\n",
        "y_test = torch.from_numpy(xy[:, :])\n",
        "\n"
      ],
      "metadata": {
        "id": "1WBKfxlL-OX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288a5af6-73e6-4d5d-b134-030eabec9dc7"
      },
      "id": "1WBKfxlL-OX0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2947, 561)\n",
            "tensor([[ 0.2572, -0.0233, -0.0147,  ..., -0.7200,  0.2768, -0.0580],\n",
            "        [ 0.2860, -0.0132, -0.1191,  ..., -0.6981,  0.2813, -0.0839],\n",
            "        [ 0.2755, -0.0261, -0.1182,  ..., -0.7028,  0.2801, -0.0793],\n",
            "        ...,\n",
            "        [ 0.3500,  0.0301, -0.1158,  ..., -0.6554,  0.2745,  0.1812],\n",
            "        [ 0.2376,  0.0185, -0.0965,  ..., -0.6597,  0.2648,  0.1876],\n",
            "        [ 0.1536, -0.0184, -0.1370,  ..., -0.6601,  0.2639,  0.1881]],\n",
            "       dtype=torch.float64)\n",
            "(2947, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"./UCI HAR Dataset/train/y_train.txt\", \"r\")\n",
        "array = []\n",
        "line = f.readline()\n",
        "index = 0\n",
        "while line:\n",
        "    line = line.strip(\"\\n\")\n",
        "    line = line.split()\n",
        "    array.append([])\n",
        "    for item in line:\n",
        "        array[index].append(float(item))\n",
        "    line = f.readline()\n",
        "    index += 1\n",
        "f.close()\n",
        "\n",
        "xy=np.array(array)\n",
        "xy=xy.astype(np.float64)\n",
        "print(xy.shape)\n",
        "y_train = torch.from_numpy(xy[:, :])\n",
        "\n",
        "\n",
        "f = open(\"./UCI HAR Dataset/train/X_train.txt\", \"r\")\n",
        "array = []\n",
        "line = f.readline()\n",
        "index = 0\n",
        "while line:\n",
        "    line = line.strip(\"\\n\")\n",
        "    line = line.split()\n",
        "    array.append([])\n",
        "    for item in line:\n",
        "        array[index].append(float(item))\n",
        "    line = f.readline()\n",
        "    index += 1\n",
        "f.close()\n",
        "\n",
        "xy=np.array(array)\n",
        "xy=xy.astype(np.float64)\n",
        "print(xy.shape)\n",
        "x_train = torch.from_numpy(xy[:, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653839e1-13a5-4d81-dc9c-d366b3311433",
        "id": "Xcip1hnjtZMV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7352, 1)\n",
            "(7352, 561)\n"
          ]
        }
      ],
      "id": "Xcip1hnjtZMV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c2a2e0b",
      "metadata": {
        "id": "5c2a2e0b"
      },
      "outputs": [],
      "source": [
        "class DTC(nn.Module):\n",
        "\n",
        "    def __init__(self,maxpooling_filter):\n",
        "        super(DTC, self).__init__()\n",
        "        \n",
        "\n",
        "        self.cnv1=nn.Conv1d(1, 1, 10)\n",
        "        self.fc1=nn.Linear(552-maxpooling_filter+1,552-maxpooling_filter+1)\n",
        "        self.fc2=nn.Linear(552-maxpooling_filter+1,552-maxpooling_filter+1)\n",
        "        self.lrel=nn.LeakyReLU()\n",
        "        self.maxpool=nn.MaxPool1d(maxpooling_filter, stride=1,return_indices=True)\n",
        "        self.maxunpool=nn.MaxUnpool1d(maxpooling_filter, stride=1)\n",
        "        self.upsample=nn.Upsample(scale_factor=(552/(553-maxpooling_filter)), mode='bilinear')\n",
        "        self.deconv1=nn.ConvTranspose1d(1, 1, 10)\n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = self.lrel(self.cnv1(x))\n",
        "        \n",
        "        x,self.indices= self.maxpool(x)\n",
        "        x = self.lrel(self.fc1(x))\n",
        "        return x,self.indices\n",
        "    def decode(self,x,indice):\n",
        "        x = self.lrel(self.fc2(x))\n",
        "        x= (self.maxunpool(x,indice))#.squeeze(dim=3)\n",
        "        \n",
        "        x= self.deconv1(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "model = DTC(520)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "loss=nn.MSELoss()"
      ],
      "metadata": {
        "id": "R9mLFD1uQzqQ"
      },
      "id": "R9mLFD1uQzqQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.float()\n",
        "x_test=x_test.float()\n",
        "y_train=y_train.float()\n",
        "y_test=y_test.float()\n",
        "y_train=y_train.view(7352,1, 1)\n",
        "x_train=x_train.view(7352,1, 561)\n",
        "x_test=x_test.view(2947,1, 561)\n",
        "y_test=y_test.view(2947,1, 1)\n",
        "#cuda0 = torch.device('cuda:0')\n",
        "#y_test.to(cuda0)\n",
        "#x_test.to(cuda0)\n",
        "#y_train.to(cuda0)\n",
        "#x_train.to(cuda0)"
      ],
      "metadata": {
        "id": "zwX1JVoPeU__"
      },
      "id": "zwX1JVoPeU__",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x_train=x_train.view(7352,1, 561)\n",
        "#x_train=x_train.float()\n",
        "x,y=model.encode(x_train)\n",
        "print(x.shape)\n",
        "print(x)\n",
        "print(x.dim())\n",
        "#input2 = torch.randn(20, 16, 50)\n",
        "#print(input2)\n",
        "\n",
        "#input = torch.arange(1, 41, dtype=torch.float32).view( 2,1, 20)\n",
        "#x=model.encode(input[1])\n",
        "#print(x.shape)\n",
        "#print(x)\n",
        "\n",
        "#print(input[1].shape)\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "t9CwPwdSdRB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95512e9d-a33f-4a44-a8ad-289437dfc247"
      },
      "id": "t9CwPwdSdRB-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7352, 1, 33])\n",
            "tensor([[[-1.1196e-04,  8.7408e-01,  4.4060e-01,  ...,  4.8807e-01,\n",
            "          -7.9237e-03,  1.3752e-01]],\n",
            "\n",
            "        [[-1.1139e-04,  8.7666e-01,  4.4275e-01,  ...,  4.8949e-01,\n",
            "          -7.9525e-03,  1.3857e-01]],\n",
            "\n",
            "        [[-1.1188e-04,  8.7444e-01,  4.4089e-01,  ...,  4.8826e-01,\n",
            "          -7.9277e-03,  1.3767e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.5139e-04,  6.9811e-01,  2.9378e-01,  ...,  3.9087e-01,\n",
            "          -5.9620e-03,  6.6101e-02]],\n",
            "\n",
            "        [[-1.5219e-04,  6.9452e-01,  2.9080e-01,  ...,  3.8889e-01,\n",
            "          -5.9221e-03,  6.4647e-02]],\n",
            "\n",
            "        [[-1.5451e-04,  6.8415e-01,  2.8214e-01,  ...,  3.8316e-01,\n",
            "          -5.8064e-03,  6.0436e-02]]], grad_fn=<LeakyReluBackward0>)\n",
            "3\n",
            "torch.Size([7352, 1, 561])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Datatrain(Dataset):\n",
        "  def __init__(self,train_x,train_y):\n",
        "    self.x = train_x\n",
        "    self.y = train_y\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index], self.y[index]"
      ],
      "metadata": {
        "id": "PQ-T192ZqPjc"
      },
      "id": "PQ-T192ZqPjc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hartrain = Datatrain(x_train,y_train)\n",
        "batch_size = 500\n",
        "data = DataLoader(hartrain,batch_size=batch_size,shuffle=True,num_workers=3)"
      ],
      "metadata": {
        "id": "iyQ0qNHJpK7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dcebe3c-6630-4804-ea77-391e081433ae"
      },
      "id": "iyQ0qNHJpK7F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = MultiStepLR(optimizer, milestones=[40,61], gamma=0.1)"
      ],
      "metadata": {
        "id": "bOrGkvj8a52F"
      },
      "id": "bOrGkvj8a52F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(50):\n",
        "  for features,labels in data:\n",
        "    optimizer.zero_grad()\n",
        "    x_pred,indice=model.encode(features)\n",
        "    \n",
        "    x_pred=model.decode(x_pred,indice)\n",
        "    \n",
        "    l=loss(x_pred,features)\n",
        "    \n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "  print(l)\n"
      ],
      "metadata": {
        "id": "uJXby5YnSAZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d659ece-67aa-48a4-f61d-2304ebd4f2fb"
      },
      "id": "uJXby5YnSAZ5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8287, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.8029, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.7513, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.7505, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.7428, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.7181, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.6831, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.6621, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.6552, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.6317, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.6207, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5986, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5937, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5768, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5622, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5479, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5367, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5143, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5079, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5060, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4921, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4772, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4683, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4586, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4592, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4265, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4223, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4218, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4224, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4014, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4172, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3944, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3753, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3804, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3840, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3628, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3719, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3560, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3451, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3532, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3535, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3409, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3314, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3203, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3357, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3289, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3273, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3221, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3098, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3123, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "x,y=hartrain[0]\n",
        "print(x)\n",
        "x1,x2=model.encode(x)\n",
        "y=model.decode(x1,x2)\n",
        "print(y)\n",
        "print (x1.shape)\n",
        "print (y.shape)\n",
        "print (loss(x,y))\n"
      ],
      "metadata": {
        "id": "Pq0SB78oceLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7807bd22-33ad-45ef-c4d3-a6202b33e151"
      },
      "id": "Pq0SB78oceLZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2886, -0.0203, -0.1329, -0.9953, -0.9831, -0.9135, -0.9951, -0.9832,\n",
            "         -0.9235, -0.9347, -0.5674, -0.7444,  0.8529,  0.6858,  0.8143, -0.9655,\n",
            "         -0.9999, -0.9999, -0.9946, -0.9942, -0.9876, -0.9432, -0.4077, -0.6793,\n",
            "         -0.6021,  0.9293, -0.8530,  0.3599, -0.0585,  0.2569, -0.2248,  0.2641,\n",
            "         -0.0952,  0.2789, -0.4651,  0.4919, -0.1909,  0.3763,  0.4351,  0.6608,\n",
            "          0.9634, -0.1408,  0.1154, -0.9852, -0.9817, -0.8776, -0.9850, -0.9844,\n",
            "         -0.8947,  0.8921, -0.1613,  0.1247,  0.9774, -0.1232,  0.0565, -0.3754,\n",
            "          0.8995, -0.9709, -0.9755, -0.9843, -0.9888, -0.9177, -1.0000, -1.0000,\n",
            "          0.1138, -0.5904,  0.5911, -0.5918,  0.5925, -0.7454,  0.7209, -0.7124,\n",
            "          0.7113, -0.9951,  0.9957, -0.9957,  0.9917,  0.5702,  0.4390,  0.9869,\n",
            "          0.0780,  0.0050, -0.0678, -0.9935, -0.9884, -0.9936, -0.9945, -0.9862,\n",
            "         -0.9928, -0.9852, -0.9920, -0.9931,  0.9898,  0.9920,  0.9905, -0.9935,\n",
            "         -0.9999, -0.9998, -0.9999, -0.9944, -0.9860, -0.9892, -0.8199, -0.7930,\n",
            "         -0.8889,  1.0000, -0.2207,  0.6368,  0.3876,  0.2414, -0.0523,  0.2642,\n",
            "          0.3734,  0.3418, -0.5698,  0.2654, -0.4779, -0.3853,  0.0336, -0.1265,\n",
            "         -0.0061, -0.0314,  0.1077, -0.9853, -0.9766, -0.9922, -0.9846, -0.9764,\n",
            "         -0.9924, -0.8670, -0.9338, -0.7476,  0.8473,  0.9149,  0.8308, -0.9672,\n",
            "         -0.9996, -0.9994, -0.9998, -0.9834, -0.9786, -0.9930,  0.0826,  0.2023,\n",
            "         -0.1688,  0.0963, -0.2750,  0.4986, -0.2203,  1.0000, -0.9730,  0.3167,\n",
            "          0.3757,  0.7234, -0.7711,  0.6902, -0.3318,  0.7096,  0.1349,  0.3011,\n",
            "         -0.0992, -0.0555, -0.0620, -0.9921, -0.9925, -0.9921, -0.9922, -0.9949,\n",
            "         -0.9926, -0.9902, -0.9867, -0.9920,  0.9944,  0.9918,  0.9894, -0.9945,\n",
            "         -0.9999, -1.0000, -0.9999, -0.9923, -0.9969, -0.9922, -0.5899, -0.6885,\n",
            "         -0.5721,  0.2924, -0.3620,  0.4055, -0.0390,  0.9893, -0.4146,  0.3916,\n",
            "          0.2823,  0.9273, -0.5724,  0.6916,  0.4683, -0.1311, -0.0872,  0.3362,\n",
            "         -0.9594, -0.9506, -0.9580, -0.9463, -0.9926, -0.9594, -0.9985, -0.9576,\n",
            "         -0.2326, -0.1732, -0.0229,  0.0948,  0.1918, -0.9594, -0.9506, -0.9580,\n",
            "         -0.9463, -0.9926, -0.9594, -0.9985, -0.9576, -0.2326, -0.1732, -0.0229,\n",
            "          0.0948,  0.1918, -0.9933, -0.9943, -0.9945, -0.9928, -0.9912, -0.9933,\n",
            "         -0.9999, -0.9929, -0.8634,  0.2831, -0.2373, -0.1054, -0.0382, -0.9690,\n",
            "         -0.9643, -0.9572, -0.9751, -0.9916, -0.9690, -0.9993, -0.9498,  0.0726,\n",
            "          0.5725, -0.7386,  0.2126,  0.4334, -0.9942, -0.9914, -0.9931, -0.9889,\n",
            "         -0.9935, -0.9942, -0.9999, -0.9945, -0.6198,  0.2928, -0.1769, -0.1458,\n",
            "         -0.1241, -0.9948, -0.9830, -0.9393, -0.9954, -0.9831, -0.9062, -0.9969,\n",
            "         -0.9845, -0.9321, -0.9938, -0.9832, -0.8851, -0.9940, -0.9934, -0.9234,\n",
            "         -0.9747, -1.0000, -0.9997, -0.9949, -0.9959, -0.9897, -0.9880, -0.9464,\n",
            "         -0.9047, -0.5913, -1.0000, -1.0000, -1.0000,  0.2525,  0.1318, -0.0521,\n",
            "          0.1421, -0.1507, -0.2205, -0.5587,  0.2468, -0.0074, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -0.9999, -0.9997, -0.9997, -1.0000, -1.0000, -1.0000,\n",
            "         -0.9999, -0.9998, -1.0000, -0.9999, -0.9997, -0.9999, -0.9999, -0.9999,\n",
            "         -0.9997, -0.9997, -0.9995, -0.9998, -0.9997, -0.9998, -0.9997, -0.9996,\n",
            "         -0.9997, -0.9998, -0.9936, -0.9995, -0.9997, -0.9996, -0.9993, -0.9979,\n",
            "         -0.9959, -0.9951, -0.9947, -0.9997, -0.9989, -0.9957, -0.9949, -0.9995,\n",
            "         -0.9923, -0.9872, -0.9897, -0.9958, -0.9909, -0.9971, -0.9938, -0.9905,\n",
            "         -0.9970, -0.9967, -0.9920, -0.9932, -0.9983, -0.9911, -0.9599, -0.9905,\n",
            "         -0.9999, -0.9998, -0.9999, -0.9930, -0.9914, -0.9962, -1.0000, -1.0000,\n",
            "         -1.0000,  1.0000, -0.2400, -1.0000,  0.8704,  0.2107,  0.2637, -0.7037,\n",
            "         -0.9037, -0.5826, -0.9363, -0.5073, -0.8055, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -0.9999, -0.9996, -0.9995, -1.0000, -1.0000, -1.0000, -0.9998,\n",
            "         -0.9995, -1.0000, -0.9999, -0.9999, -0.9999, -0.9998, -0.9999, -0.9997,\n",
            "         -0.9997, -0.9996, -0.9998, -0.9999, -0.9998, -0.9997, -0.9996, -0.9999,\n",
            "         -0.9998, -0.9994, -0.9998, -1.0000, -0.9999, -0.9998, -0.9998, -0.9988,\n",
            "         -0.9986, -0.9996, -1.0000, -0.9998, -0.9987, -0.9998, -0.9999, -0.9866,\n",
            "         -0.9818, -0.9895, -0.9850, -0.9739, -0.9940, -0.9865, -0.9836, -0.9924,\n",
            "         -0.9805, -0.9723, -0.9949, -0.9976, -0.9841, -0.9943, -0.9853, -0.9999,\n",
            "         -0.9997, -0.9999, -0.9903, -0.9948, -0.9944, -0.7124, -0.6448, -0.8390,\n",
            "         -1.0000, -1.0000, -1.0000, -0.2575,  0.0979,  0.5472,  0.3773,  0.1341,\n",
            "          0.2734, -0.0913, -0.4843, -0.7829, -0.9999, -0.9999, -1.0000, -1.0000,\n",
            "         -0.9999, -1.0000, -0.9999, -1.0000, -0.9999, -1.0000, -0.9999, -1.0000,\n",
            "         -0.9999, -1.0000, -0.9995, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998,\n",
            "         -0.9983, -0.9990, -0.9996, -1.0000, -0.9999, -0.9984, -0.9996, -1.0000,\n",
            "         -1.0000, -1.0000, -0.9999, -1.0000, -0.9999, -0.9998, -0.9991, -0.9999,\n",
            "         -1.0000, -0.9999, -0.9999, -0.9994, -0.9999, -1.0000, -0.9522, -0.9561,\n",
            "         -0.9489, -0.9743, -0.9257, -0.9522, -0.9983, -0.9733, -0.6464, -0.7931,\n",
            "         -0.0884, -0.4365, -0.7968, -0.9937, -0.9938, -0.9920, -0.9934, -0.9882,\n",
            "         -0.9937, -0.9999, -0.9914, -1.0000, -0.9365,  0.3470, -0.5161, -0.8028,\n",
            "         -0.9801, -0.9613, -0.9737, -0.9523, -0.9895, -0.9801, -0.9992, -0.9927,\n",
            "         -0.7013, -1.0000, -0.1290,  0.5862,  0.3746, -0.9920, -0.9907, -0.9899,\n",
            "         -0.9924, -0.9910, -0.9920, -0.9999, -0.9905, -0.8713, -1.0000, -0.0743,\n",
            "         -0.2987, -0.7103, -0.1128,  0.0304, -0.4648, -0.0184, -0.8412,  0.1799,\n",
            "         -0.0586]])\n",
            "tensor([[-0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.9892, -0.9999,\n",
            "         -0.9899, -0.9734, -0.9903, -1.0044, -0.9701, -0.9637, -0.9705, -0.9943,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094, -0.3094,\n",
            "         -0.3094]], grad_fn=<SqueezeBackward1>)\n",
            "torch.Size([1, 33])\n",
            "torch.Size([1, 561])\n",
            "tensor(0.4319, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "optimizer2 = torch.optim.SGD(model.parameters(),lr=0.01)\n",
        "model.train()"
      ],
      "metadata": {
        "id": "47uyi7bOsYI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24056bf0-c7a4-424a-e991-144b063e2b9c"
      },
      "id": "47uyi7bOsYI2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DTC(\n",
              "  (cnv1): Conv1d(1, 1, kernel_size=(10,), stride=(1,))\n",
              "  (fc1): Linear(in_features=33, out_features=33, bias=True)\n",
              "  (fc2): Linear(in_features=33, out_features=33, bias=True)\n",
              "  (lrel): LeakyReLU(negative_slope=0.01)\n",
              "  (maxpool): MaxPool1d(kernel_size=520, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (maxunpool): MaxUnpool1d(kernel_size=(520,), stride=(1,), padding=(0,))\n",
              "  (upsample): Upsample(scale_factor=16.727272727272727, mode=bilinear)\n",
              "  (deconv1): ConvTranspose1d(1, 1, kernel_size=(10,), stride=(1,))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "dlHZAahAsc5f"
      },
      "id": "dlHZAahAsc5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters=6\n",
        "for epoch in range(50):\n",
        "  for features,labels in data:\n",
        "    optimizer2.zero_grad()\n",
        "    model2 = AgglomerativeClustering(\n",
        "        n_clusters=n_clusters, linkage=\"complete\"\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "      x_pred,indice=model.encode(features)\n",
        "      a,b,c=features.shape\n",
        "      x_pred=x_pred.view(a,33)\n",
        "      y_predict=model2.fit_predict(x_pred)\n",
        "      clf = NearestCentroid()\n",
        "      clf.fit(x_pred, y_predict)\n",
        "    qij = torch.ones([batch_size, n_clusters], dtype=torch.float64, requires_grad=True)\n",
        "    pij = torch.ones([batch_size, n_clusters], dtype=torch.float64, requires_grad=True)\n",
        "    fj = torch.ones([n_clusters,1], dtype=torch.float64, requires_grad=True)\n",
        "    sigma1=0   \n",
        "    for i , feature in enumerate(features):\n",
        "      sigma1=0\n",
        "      for j in range(n_clusters):\n",
        "        sigma1+=((1+torch.sqrt(torch.sum((x_pred[i]-clf.centroids_[j])**2)))**-1)\n",
        "      for j in range(n_clusters):\n",
        "        qij[i][j] = (((1+torch.sqrt(torch.sum((x_pred[i]-clf.centroids_[j])**2)))**-1)/sigma1) \n",
        "    for j in range(n_clusters):\n",
        "      for i , feature in enumerate(features):\n",
        "        print (qij.shape)\n",
        "        fj[j]+=qij[i][j]   \n",
        "    sigma1=0\n",
        "    cluster_loss=0\n",
        "    for i , feature in enumerate(features):\n",
        "      for j in range(n_clusters):\n",
        "        cluster_loss+=pij[i][j]*torch.log(pij[i][j]/qij[i][j])\n",
        "    cluster_loss.backward()\n",
        "    optimizer2.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "qwpR6FDWM6C4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "7c3c6bde-e66a-4157-f6a8-fb84b9c66b8b"
      },
      "id": "qwpR6FDWM6C4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-44cbe63a7139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msigma1\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroids_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mqij\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroids_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msigma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: a view of a leaf Variable that requires grad is being used in an in-place operation."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.randn(1, 23)\n",
        "b=torch.randn(1, 23)\n",
        "print(a)\n",
        "print(b)\n",
        "c=torch.sqrt(torch.sum((a-b)**2))\n",
        "print (c)"
      ],
      "metadata": {
        "id": "Vyqa4JnKYqCK"
      },
      "id": "Vyqa4JnKYqCK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EQhuqcepqrTL"
      },
      "id": "EQhuqcepqrTL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.centroids_.shape)\n"
      ],
      "metadata": {
        "id": "KcOaNg_gujUa"
      },
      "id": "KcOaNg_gujUa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tcMagnI9qs-2"
      },
      "id": "tcMagnI9qs-2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}